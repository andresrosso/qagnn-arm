nlp-lab
pid: 1034996
conda env: haystack-py310
screen: 

gpu: 0

Namespace(ent_emb=['ddb'], dataset='medqa_usmle', inhouse=False, inhouse_train_qids='data/medqa_usmle/inhouse_split_qids.txt', train_statements='data/medqa_usmle/statement/train.statement.jsonl', dev_statements='data/medqa_usmle/statement/dev.statement.jsonl', test_statements='data/medqa_usmle/statement/test.statement.jsonl', max_seq_len=512, encoder='cambridgeltl/SapBERT-from-PubMedBERT-fulltext', encoder_layer=-1, encoder_lr=5e-05, loss='cross_entropy', optim='radam', lr_schedule='fixed', batch_size=128, warmup_steps=150, max_grad_norm=1.0, weight_decay=0.01, n_epochs=15, max_epochs_before_stop=10, log_interval=10, cuda=True, seed=0, debug=False, mode='train', save_dir='saved_models/medqa_usmle/enc-sapbert__k5__gnndim200__bs128__seed0__20230418_171453', save_model=True, load_model_path=None, num_relation=34, train_adj='data/medqa_usmle/graph/train.graph.adj.pk', dev_adj='data/medqa_usmle/graph/dev.graph.adj.pk', test_adj='data/medqa_usmle/graph/test.graph.adj.pk', use_cache=True, k=5, att_head_num=2, gnn_dim=200, fc_dim=200, fc_layer_num=0, freeze_ent_emb=True, max_node_num=200, simple=False, subsample=1.0, init_range=0.02, dropouti=0.2, dropoutg=0.2, dropoutf=0.2, decoder_lr=0.001, mini_batch_size=2, eval_batch_size=2, unfreeze_epoch=0, refreeze_epoch=10000, fp16=True, drop_partial_batch=False, fill_partial_batch=False, ent_emb_paths=['data/ddb/ent_emb.npy'])
| num_concepts: 9958 |
train_statement_path data/medqa_usmle/statement/train.statement.jsonl
num_choice 4
| ori_adj_len: mu 26.49 sigma 29.73 | adj_len: 27.43 | prune_rate： 0.00 | qc_num: 4.57 | ac_num: 1.06 |
| ori_adj_len: mu 25.20 sigma 28.18 | adj_len: 26.20 | prune_rate： 0.00 | qc_num: 4.34 | ac_num: 1.07 |
| ori_adj_len: mu 26.09 sigma 28.17 | adj_len: 27.06 | prune_rate： 0.00 | qc_num: 4.61 | ac_num: 1.06 |
args.num_relation 34
parameters:
	concept_emb.emb.weight                       	fixed	torch.Size([9958, 768])	device:cuda:0
	concept_emb.cpt_transform.weight             	trainable	torch.Size([200, 768])	device:cuda:0
	concept_emb.cpt_transform.bias               	trainable	torch.Size([200])	device:cuda:0
	svec2nvec.weight                             	trainable	torch.Size([200, 768])	device:cuda:0
	svec2nvec.bias                               	trainable	torch.Size([200])	device:cuda:0
	gnn.emb_node_type.weight                     	trainable	torch.Size([100, 4])	device:cuda:0
	gnn.emb_node_type.bias                       	trainable	torch.Size([100])	device:cuda:0
	gnn.emb_score.weight                         	trainable	torch.Size([100, 100])	device:cuda:0
	gnn.emb_score.bias                           	trainable	torch.Size([100])	device:cuda:0
	gnn.edge_encoder.0.weight                    	trainable	torch.Size([200, 43])	device:cuda:0
	gnn.edge_encoder.0.bias                      	trainable	torch.Size([200])	device:cuda:0
	gnn.edge_encoder.1.weight                    	trainable	torch.Size([200])	device:cuda:0
	gnn.edge_encoder.1.bias                      	trainable	torch.Size([200])	device:cuda:0
	gnn.edge_encoder.3.weight                    	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.edge_encoder.3.bias                      	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.0.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:0
	gnn.gnn_layers.0.linear_key.bias             	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.0.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:0
	gnn.gnn_layers.0.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.0.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:0
	gnn.gnn_layers.0.linear_query.bias           	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.0.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.gnn_layers.0.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.0.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.0.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.0.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.gnn_layers.0.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.1.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:0
	gnn.gnn_layers.1.linear_key.bias             	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.1.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:0
	gnn.gnn_layers.1.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.1.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:0
	gnn.gnn_layers.1.linear_query.bias           	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.1.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.gnn_layers.1.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.1.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.1.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.1.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.gnn_layers.1.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.2.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:0
	gnn.gnn_layers.2.linear_key.bias             	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.2.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:0
	gnn.gnn_layers.2.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.2.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:0
	gnn.gnn_layers.2.linear_query.bias           	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.2.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.gnn_layers.2.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.2.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.2.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.2.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.gnn_layers.2.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.3.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:0
	gnn.gnn_layers.3.linear_key.bias             	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.3.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:0
	gnn.gnn_layers.3.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.3.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:0
	gnn.gnn_layers.3.linear_query.bias           	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.3.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.gnn_layers.3.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.3.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.3.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.3.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.gnn_layers.3.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.4.linear_key.weight           	trainable	torch.Size([200, 600])	device:cuda:0
	gnn.gnn_layers.4.linear_key.bias             	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.4.linear_msg.weight           	trainable	torch.Size([200, 600])	device:cuda:0
	gnn.gnn_layers.4.linear_msg.bias             	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.4.linear_query.weight         	trainable	torch.Size([200, 400])	device:cuda:0
	gnn.gnn_layers.4.linear_query.bias           	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.4.mlp.0.weight                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.gnn_layers.4.mlp.0.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.4.mlp.1.weight                	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.4.mlp.1.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.gnn_layers.4.mlp.3.weight                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.gnn_layers.4.mlp.3.bias                  	trainable	torch.Size([200])	device:cuda:0
	gnn.Vh.weight                                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.Vh.bias                                  	trainable	torch.Size([200])	device:cuda:0
	gnn.Vx.weight                                	trainable	torch.Size([200, 200])	device:cuda:0
	gnn.Vx.bias                                  	trainable	torch.Size([200])	device:cuda:0
	pooler.w_qs.weight                           	trainable	torch.Size([200, 768])	device:cuda:0
	pooler.w_qs.bias                             	trainable	torch.Size([200])	device:cuda:0
	pooler.w_ks.weight                           	trainable	torch.Size([200, 200])	device:cuda:0
	pooler.w_ks.bias                             	trainable	torch.Size([200])	device:cuda:0
	pooler.w_vs.weight                           	trainable	torch.Size([200, 200])	device:cuda:0
	pooler.w_vs.bias                             	trainable	torch.Size([200])	device:cuda:0
	fc.layers.0-Linear.weight                    	trainable	torch.Size([1, 1168])	device:cuda:0
	fc.layers.0-Linear.bias                      	trainable	torch.Size([1])	device:cuda:0
	total: 2690369

-----------------------------------------------------------------------
Using fp16 training
| step     9 |  lr: 0.0000500 | loss  1.3918 | ms/batch 164474.59 |
| step    19 |  lr: 0.0000500 | loss  1.3953 | ms/batch 164633.19 |
| step    29 |  lr: 0.0000500 | loss  1.3948 | ms/batch 164393.03 |
| step    39 |  lr: 0.0000500 | loss  1.3996 | ms/batch 164435.87 |
| step    49 |  lr: 0.0000500 | loss  1.4016 | ms/batch 164313.24 |
| step    59 |  lr: 0.0000500 | loss  1.3907 | ms/batch 164322.78 |
| step    69 |  lr: 0.0000500 | loss  1.3913 | ms/batch 164377.87 |
| step    79 |  lr: 0.0000500 | loss  1.3896 | ms/batch 156426.18 |
-----------------------------------------------------------------------
| epoch   0 | step    80 | dev_acc  0.2618 | test_acc  0.2663 |
-----------------------------------------------------------------------
model saved to saved_models/medqa_usmle/enc-sapbert__k5__gnndim200__bs128__seed0__20230418_171453/model.pt.0
| step    89 |  lr: 0.0000500 | loss  1.3973 | ms/batch 164428.92 |
| step    99 |  lr: 0.0000500 | loss  1.3911 | ms/batch 164442.75 |
| step   109 |  lr: 0.0000500 | loss  1.3894 | ms/batch 164368.96 |
| step   119 |  lr: 0.0000500 | loss  1.3895 | ms/batch 164438.46 |
| step   129 |  lr: 0.0000500 | loss  1.3858 | ms/batch 164380.82 |
| step   139 |  lr: 0.0000500 | loss  1.3883 | ms/batch 164411.04 |
| step   149 |  lr: 0.0000500 | loss  1.3857 | ms/batch 164351.70 |
| step   159 |  lr: 0.0000500 | loss  1.3834 | ms/batch 156371.64 |
-----------------------------------------------------------------------
| epoch   1 | step   160 | dev_acc  0.3019 | test_acc  0.2828 |
-----------------------------------------------------------------------
model saved to saved_models/medqa_usmle/enc-sapbert__k5__gnndim200__bs128__seed0__20230418_171453/model.pt.1
| step   169 |  lr: 0.0000500 | loss  1.3733 | ms/batch 164579.78 |
| step   179 |  lr: 0.0000500 | loss  1.3677 | ms/batch 164420.97 |
| step   189 |  lr: 0.0000500 | loss  1.3641 | ms/batch 164531.76 |
| step   199 |  lr: 0.0000500 | loss  1.3636 | ms/batch 164520.33 |
| step   209 |  lr: 0.0000500 | loss  1.3685 | ms/batch 164582.26 |
| step   219 |  lr: 0.0000500 | loss  1.3751 | ms/batch 164478.62 |
| step   229 |  lr: 0.0000500 | loss  1.3719 | ms/batch 164599.12 |
| step   239 |  lr: 0.0000500 | loss  1.3583 | ms/batch 156526.03 |
-----------------------------------------------------------------------
| epoch   2 | step   240 | dev_acc  0.3278 | test_acc  0.3142 |
-----------------------------------------------------------------------
model saved to saved_models/medqa_usmle/enc-sapbert__k5__gnndim200__bs128__seed0__20230418_171453/model.pt.2
| step   249 |  lr: 0.0000500 | loss  1.3281 | ms/batch 164597.86 |
| step   259 |  lr: 0.0000500 | loss  1.3243 | ms/batch 164579.85 |
| step   269 |  lr: 0.0000500 | loss  1.3091 | ms/batch 164702.40 |
| step   279 |  lr: 0.0000500 | loss  1.3184 | ms/batch 164741.57 |
| step   289 |  lr: 0.0000500 | loss  1.3141 | ms/batch 164808.68 |
| step   299 |  lr: 0.0000500 | loss  1.3235 | ms/batch 164915.85 |
| step   309 |  lr: 0.0000500 | loss  1.3269 | ms/batch 164648.78 |
| step   319 |  lr: 0.0000500 | loss  1.3176 | ms/batch 156613.31 |
-----------------------------------------------------------------------
| epoch   3 | step   320 | dev_acc  0.3436 | test_acc  0.3386 |
-----------------------------------------------------------------------
model saved to saved_models/medqa_usmle/enc-sapbert__k5__gnndim200__bs128__seed0__20230418_171453/model.pt.3
| step   329 |  lr: 0.0000500 | loss  1.2601 | ms/batch 164716.19 |
| step   339 |  lr: 0.0000500 | loss  1.2194 | ms/batch 164611.94 |
| step   349 |  lr: 0.0000500 | loss  1.2405 | ms/batch 164665.54 |
| step   359 |  lr: 0.0000500 | loss  1.1856 | ms/batch 164846.60 |
| step   369 |  lr: 0.0000500 | loss  1.1989 | ms/batch 164617.14 |
| step   379 |  lr: 0.0000500 | loss  1.2568 | ms/batch 164774.33 |
| step   389 |  lr: 0.0000500 | loss  1.2179 | ms/batch 164592.16 |
| step   399 |  lr: 0.0000500 | loss  1.2235 | ms/batch 156665.13 |
-----------------------------------------------------------------------
| epoch   4 | step   400 | dev_acc  0.3428 | test_acc  0.3606 |
-----------------------------------------------------------------------
model saved to saved_models/medqa_usmle/enc-sapbert__k5__gnndim200__bs128__seed0__20230418_171453/model.pt.4
| step   409 |  lr: 0.0000500 | loss  1.1207 | ms/batch 164607.43 |
| step   419 |  lr: 0.0000500 | loss  1.0821 | ms/batch 164611.17 |
| step   429 |  lr: 0.0000500 | loss  1.1000 | ms/batch 164572.60 |
| step   439 |  lr: 0.0000500 | loss  1.0740 | ms/batch 164542.73 |
| step   449 |  lr: 0.0000500 | loss  1.0950 | ms/batch 164529.63 |
| step   459 |  lr: 0.0000500 | loss  1.1143 | ms/batch 164503.83 |
| step   469 |  lr: 0.0000500 | loss  1.0857 | ms/batch 164392.37 |
| step   479 |  lr: 0.0000500 | loss  1.0884 | ms/batch 156492.53 |
-----------------------------------------------------------------------
| epoch   5 | step   480 | dev_acc  0.3522 | test_acc  0.3551 |
-----------------------------------------------------------------------
model saved to saved_models/medqa_usmle/enc-sapbert__k5__gnndim200__bs128__seed0__20230418_171453/model.pt.5
| step   489 |  lr: 0.0000500 | loss  0.9567 | ms/batch 164324.72 |
| step   499 |  lr: 0.0000500 | loss  0.9695 | ms/batch 164392.90 |
| step   509 |  lr: 0.0000500 | loss  0.9276 | ms/batch 164476.84 |
| step   519 |  lr: 0.0000500 | loss  0.9302 | ms/batch 164423.02 |
| step   529 |  lr: 0.0000500 | loss  0.9710 | ms/batch 164349.23 |
| step   539 |  lr: 0.0000500 | loss  0.9526 | ms/batch 164483.38 |
| step   549 |  lr: 0.0000500 | loss  0.9619 | ms/batch 164516.77 |
| step   559 |  lr: 0.0000500 | loss  0.9870 | ms/batch 156634.28 |
-----------------------------------------------------------------------
| epoch   6 | step   560 | dev_acc  0.3530 | test_acc  0.3755 |
-----------------------------------------------------------------------
model saved to saved_models/medqa_usmle/enc-sapbert__k5__gnndim200__bs128__seed0__20230418_171453/model.pt.6
| step   569 |  lr: 0.0000500 | loss  0.7668 | ms/batch 164478.19 |
| step   579 |  lr: 0.0000500 | loss  0.7856 | ms/batch 164541.74 |
| step   589 |  lr: 0.0000500 | loss  0.7865 | ms/batch 164527.04 |
| step   599 |  lr: 0.0000500 | loss  0.7950 | ms/batch 164562.84 |
| step   609 |  lr: 0.0000500 | loss  0.8320 | ms/batch 164369.97 |
| step   619 |  lr: 0.0000500 | loss  0.8329 | ms/batch 164581.30 |
| step   629 |  lr: 0.0000500 | loss  0.8132 | ms/batch 164497.82 |
| step   639 |  lr: 0.0000500 | loss  0.8386 | ms/batch 156343.19 |
-----------------------------------------------------------------------
| epoch   7 | step   640 | dev_acc  0.3695 | test_acc  0.3614 |
-----------------------------------------------------------------------
model saved to saved_models/medqa_usmle/enc-sapbert__k5__gnndim200__bs128__seed0__20230418_171453/model.pt.7
| step   649 |  lr: 0.0000500 | loss  0.6606 | ms/batch 164479.50 |
| step   659 |  lr: 0.0000500 | loss  0.6320 | ms/batch 164590.66 |
| step   669 |  lr: 0.0000500 | loss  0.6288 | ms/batch 164584.25 |
| step   679 |  lr: 0.0000500 | loss  0.6412 | ms/batch 164623.24 |
| step   689 |  lr: 0.0000500 | loss  0.6644 | ms/batch 164507.49 |
| step   699 |  lr: 0.0000500 | loss  0.6841 | ms/batch 164617.96 |
| step   709 |  lr: 0.0000500 | loss  0.6879 | ms/batch 164567.17 |
| step   719 |  lr: 0.0000500 | loss  0.6694 | ms/batch 156624.83 |
-----------------------------------------------------------------------
| epoch   8 | step   720 | dev_acc  0.3734 | test_acc  0.3739 |
-----------------------------------------------------------------------
model saved to saved_models/medqa_usmle/enc-sapbert__k5__gnndim200__bs128__seed0__20230418_171453/model.pt.8
| step   729 |  lr: 0.0000500 | loss  0.4976 | ms/batch 164746.32 |
| step   739 |  lr: 0.0000500 | loss  0.5321 | ms/batch 164633.91 |
| step   749 |  lr: 0.0000500 | loss  0.5306 | ms/batch 164612.30 |
| step   759 |  lr: 0.0000500 | loss  0.5035 | ms/batch 164887.19 |
| step   769 |  lr: 0.0000500 | loss  0.5751 | ms/batch 164999.40 |
| step   779 |  lr: 0.0000500 | loss  0.5508 | ms/batch 164843.12 |
| step   789 |  lr: 0.0000500 | loss  0.5555 | ms/batch 165176.91 |
| step   799 |  lr: 0.0000500 | loss  0.5919 | ms/batch 157298.80 |
-----------------------------------------------------------------------
| epoch   9 | step   800 | dev_acc  0.3695 | test_acc  0.3700 |
-----------------------------------------------------------------------
model saved to saved_models/medqa_usmle/enc-sapbert__k5__gnndim200__bs128__seed0__20230418_171453/model.pt.9
| step   809 |  lr: 0.0000500 | loss  0.4120 | ms/batch 164679.45 |
| step   819 |  lr: 0.0000500 | loss  0.3870 | ms/batch 164666.52 |
| step   829 |  lr: 0.0000500 | loss  0.3983 | ms/batch 164801.30 |
| step   839 |  lr: 0.0000500 | loss  0.4702 | ms/batch 164772.25 |
| step   849 |  lr: 0.0000500 | loss  0.4254 | ms/batch 164867.03 |
| step   859 |  lr: 0.0000500 | loss  0.4514 | ms/batch 165290.51 |
| step   869 |  lr: 0.0000500 | loss  0.4784 | ms/batch 164716.54 |
| step   879 |  lr: 0.0000500 | loss  0.4506 | ms/batch 156912.85 |
-----------------------------------------------------------------------
| epoch  10 | step   880 | dev_acc  0.3774 | test_acc  0.3731 |
-----------------------------------------------------------------------
model saved to saved_models/medqa_usmle/enc-sapbert__k5__gnndim200__bs128__seed0__20230418_171453/model.pt.10
| step   889 |  lr: 0.0000500 | loss  0.3343 | ms/batch 164671.50 |
| step   899 |  lr: 0.0000500 | loss  0.3138 | ms/batch 164570.40 |
| step   909 |  lr: 0.0000500 | loss  0.3531 | ms/batch 164615.92 |
| step   919 |  lr: 0.0000500 | loss  0.3421 | ms/batch 164506.94 |
| step   929 |  lr: 0.0000500 | loss  0.3537 | ms/batch 164423.26 |
| step   939 |  lr: 0.0000500 | loss  0.3548 | ms/batch 164365.41 |
| step   949 |  lr: 0.0000500 | loss  0.3865 | ms/batch 164546.96 |
| step   959 |  lr: 0.0000500 | loss  0.3608 | ms/batch 156621.73 |
-----------------------------------------------------------------------
| epoch  11 | step   960 | dev_acc  0.3766 | test_acc  0.3841 |
-----------------------------------------------------------------------
model saved to saved_models/medqa_usmle/enc-sapbert__k5__gnndim200__bs128__seed0__20230418_171453/model.pt.11
| step   969 |  lr: 0.0000500 | loss  0.2574 | ms/batch 164419.30 |
| step   979 |  lr: 0.0000500 | loss  0.2608 | ms/batch 164435.70 |
| step   989 |  lr: 0.0000500 | loss  0.2973 | ms/batch 164445.72 |
| step   999 |  lr: 0.0000500 | loss  0.2896 | ms/batch 164303.86 |
| step  1009 |  lr: 0.0000500 | loss  0.2612 | ms/batch 164380.40 |
| step  1019 |  lr: 0.0000500 | loss  0.2917 | ms/batch 164530.01 |
| step  1029 |  lr: 0.0000500 | loss  0.3116 | ms/batch 164602.38 |
| step  1039 |  lr: 0.0000500 | loss  0.3024 | ms/batch 156560.39 |
-----------------------------------------------------------------------
| epoch  12 | step  1040 | dev_acc  0.3664 | test_acc  0.3904 |
-----------------------------------------------------------------------
model saved to saved_models/medqa_usmle/enc-sapbert__k5__gnndim200__bs128__seed0__20230418_171453/model.pt.12
| step  1049 |  lr: 0.0000500 | loss  0.2123 | ms/batch 164581.68 |
| step  1059 |  lr: 0.0000500 | loss  0.2288 | ms/batch 164416.47 |
| step  1069 |  lr: 0.0000500 | loss  0.2501 | ms/batch 164366.62 |
| step  1079 |  lr: 0.0000500 | loss  0.2331 | ms/batch 164434.05 |
| step  1089 |  lr: 0.0000500 | loss  0.2453 | ms/batch 164422.58 |
| step  1099 |  lr: 0.0000500 | loss  0.2381 | ms/batch 164561.02 |
| step  1109 |  lr: 0.0000500 | loss  0.2519 | ms/batch 164507.81 |
| step  1119 |  lr: 0.0000500 | loss  0.2390 | ms/batch 156560.49 |
-----------------------------------------------------------------------
| epoch  13 | step  1120 | dev_acc  0.3876 | test_acc  0.3920 |
-----------------------------------------------------------------------
model saved to saved_models/medqa_usmle/enc-sapbert__k5__gnndim200__bs128__seed0__20230418_171453/model.pt.13
| step  1129 |  lr: 0.0000500 | loss  0.1625 | ms/batch 164547.95 |
| step  1139 |  lr: 0.0000500 | loss  0.1697 | ms/batch 164487.97 |
| step  1149 |  lr: 0.0000500 | loss  0.1844 | ms/batch 164588.39 |
